{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9293da8a-45ab-44fc-8bbf-8cf0bb2d467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "openai.api_key = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "350ae9ef-2f74-451e-8e91-d77b681701bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import tiktoken\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "558b3b50-2592-400b-a96e-f1c307908006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset into a pandas dataframe\n",
    "dataset_path = \"./wiki_movie_plots_deduped.csv\"\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "814f83ad-f282-4595-bd72-e0e83f49489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for the most recent 5000 American movies\n",
    "movies = df[df[\"Origin/Ethnicity\"] == \"American\"].sort_values(\"Release Year\", ascending=False).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab71ad56-467e-48a8-a6c8-89c66e320db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movie plots\n",
    "movie_plots = movies[\"Plot\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1902cdc-8133-4844-88b2-2b044acc13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tiktoken encoding instance for the \"text-embedding-3-small\" model\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19125991-8ec2-4d49-8aee-af216a3315b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate token number for the first movie plot\n",
    "len(enc.encode(movie_plots[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca51eb8-564c-4a7b-b2da-d2ad0349ee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count:  3620448\n"
     ]
    }
   ],
   "source": [
    "# calculate all movie plots' token count with tiktoken\n",
    "total_tokens = sum([len(enc.encode(plot)) for plot in movie_plots])\n",
    "print(\"Total token count: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6771bca-829b-49c6-beb1-888fdc2e5dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost $0.07\n"
     ]
    }
   ],
   "source": [
    "# Calculate cost for embeddings. Check website for up-to-date costs! https://openai.com/api/pricing/\n",
    "cost = total_tokens * (.02 / 1000000)\n",
    "print(f\"Estimated cost ${cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4f081-e1c5-41dc-88a9-ae301e3e3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for running 1 embedding for a given text:\n",
    "res = openai.embeddings.create(input=\"candy canes\", model=\"text-embedding-3-small\")\n",
    "res.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0506ce13-5c4d-425e-b311-7ee711eb703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting one embedding for a given text\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "\n",
    "    # replace newlines, which can negatively affect performance\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    return openai.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "627ac781-0445-4593-9e09-db589d97c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a cache of embeddings to avoid recomputing\n",
    "# Cache is a dict of tuples(text, model) -> embedding, saved as a pickle file\n",
    "# Adopted from OpenAI docs!\n",
    "\n",
    "# Set path to the embedding cache file, which is a pickle file.\n",
    "# Pickle is a standard python library that makes it easy to save data to a file and read it back from a file.\n",
    "embedding_cache_path = \"movie_embeddings.pkl\"\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, otherwise request it via the API\n",
    "def embedding_from_string(\n",
    "    string,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    embedding_cache=embedding_cache\n",
    "):\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing and unneccesary costs.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)] = get_embedding(string, model)\n",
    "        print(f\"GOT EMBEDDING FROM OPENAI FOR {string[:20]}\")\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f385e54-0529-4695-ac6a-318a0c92b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING!!! Running this function will potentionally cost the amount of money calculated above!!\n",
    "plot_embeddings = [embedding_from_string(plot, model=\"text-embedding-3-small\", embedding_cache) for plot in movie_plots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "707dfe9b-605e-4282-aab2-0fd06cc78465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plot_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0021b10a-782b-4c45-b9ee-37220332a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomic import atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b51e9a8e-4284-441a-a626-6511f3e5fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important that my movies array has the same order as my plot_embeddings array. Otherwise, when I plot the plot_embeddings \n",
    "# data on the atlas map and add extra info (title, genre) from the movies array, they would not match up with each other.\n",
    "# Other option would be to store the embeddings in a vector store or at least in the df (dataframe) itself to make sure\n",
    "# they are synced. Here, I just created a dictionary that has the same order as the plot_embeddings dataset.\n",
    "data = movies[[\"Title\", \"Genre\"]].to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c2aa430-6106-4aa5-9ec2-85f3b81f962b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-01 19:51:04.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m98\u001b[0m - \u001b[33m\u001b[1mAn ID field was not specified in your data so one was generated for you in insertion order.\u001b[0m\n",
      "\u001b[32m2024-06-01 19:51:07.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m918\u001b[0m - \u001b[1mCreating dataset `experimental-arora`\u001b[0m\n",
      "\u001b[32m2024-06-01 19:51:08.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mUploading data to Atlas.\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-06-01 19:51:10.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1597\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2024-06-01 19:51:10.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m`csernusszilvi/experimental-arora`: Data upload succeeded to dataset`\u001b[0m\n",
      "\u001b[32m2024-06-01 19:51:11.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1164\u001b[0m - \u001b[33m\u001b[1mYou did not specify the `topic_label_field` option in your topic_model, your dataset will not contain auto-labeled topics.\u001b[0m\n",
      "\u001b[32m2024-06-01 19:51:12.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1301\u001b[0m - \u001b[1mCreated map `experimental-arora` in dataset `csernusszilvi/experimental-arora`: https://atlas.nomic.ai/data/csernusszilvi/experimental-arora/map\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <strong><a href=\"https://atlas.nomic.ai/data/project/9067cefc-afe7-4646-8848-b47c6cd8c933\">experimental-arora</strong></a>\n",
       "            <br>\n",
       "             5000 datums inserted.\n",
       "            <br>\n",
       "            1 index built.\n",
       "            <br><strong>Projections</strong>\n",
       "<ul>\n",
       "<li>experimental-arora. Status Indexing. <a target=\"_blank\" href=\"https://atlas.nomic.ai/data/csernusszilvi/experimental-arora/map\">view online</a></li></ul>"
      ],
      "text/plain": [
       "AtlasDataset: <{'id': '9067cefc-afe7-4646-8848-b47c6cd8c933', 'owner': '6b6ff7ef-3a0c-4196-9ca4-3d705687120a', 'project_name': 'experimental-arora', 'creator': 'auth0|665b4a2a616aa781ae850480', 'description': '', 'is_public': True, 'is_public_to_org': True, 'project_fields': ['Title', 'Genre', 'id_', '_embeddings'], 'unique_id_field': 'id_', 'modality': 'embedding', 'total_datums_in_project': 5000, 'created_timestamp': '2024-06-01T18:51:07.672704+00:00', 'slug': 'experimental-arora', 'atlas_indices': [{'id': '20714c31-4a73-40dc-adff-f9c0f69c830b', 'project_id': '9067cefc-afe7-4646-8848-b47c6cd8c933', 'index_name': 'experimental-arora', 'indexed_field': None, 'created_timestamp': '2024-06-01T18:51:11.755507+00:00', 'updated_timestamp': '2024-06-01T18:51:11.755507+00:00', 'atoms': ['embedding'], 'colorable_fields': ['Title', 'Genre'], 'embedders': [], 'nearest_neighbor_indices': [{'id': 'ed9e19f3-9b4f-4344-b487-ae8dc764486f', 'index_name': 'NomicOrganize', 'ready': False, 'hyperparameters': {'M': 16, 'space': 'l2', 'ef_construction': 100}, 'atom_strategies': ['embedding']}], 'projections': [{'id': '9da0f349-6bc2-4ee0-ba19-ba86cd067cfb', 'projection_name': 'NomicProject', 'ready': False, 'hyperparameters': {'rho': 0.0, 'model': 'nomic-project-v2', 'spread': 1, 'n_noise': None, 'min_dist': 0.4, 'n_epochs': 50, 'n_neighbors': 5, 'n_init_epochs': 20, 'local_neighborhood_size': 15}, 'atom_strategies': ['embedding'], 'created_timestamp': '2024-06-01T18:51:11.767356+00:00', 'updated_timestamp': '2024-06-01T18:51:11.767356+00:00', 'thumbnail': 'https://atlas-content-production.s3.amazonaws.com/projects/9067cefc-afe7-4646-8848-b47c6cd8c933/9da0f349-6bc2-4ee0-ba19-ba86cd067cfb/map.png', 'og_image': 'https://atlas-content-production.s3.amazonaws.com/projects/9067cefc-afe7-4646-8848-b47c6cd8c933/9da0f349-6bc2-4ee0-ba19-ba86cd067cfb/og-map.png'}]}], 'insert_update_delete_lock': True, 'access_role': 'ADMIN', 'schema': '/////5ABAAAQAAAAAAAKAA4ABgAFAAgACgAAAAABBAAQAAAAAAAKAAwAAAAEAAgACgAAAGAAAAAEAAAAAQAAAAwAAAAIAAwABAAIAAgAAAAIAAAAFAAAAAoAAABwcm9qZWN0X2lkAAAkAAAAOTA2N2NlZmMtYWZlNy00NjQ2LTg4NDgtYjQ3YzZjZDhjOTMzAAAAAAQAAADQAAAAlAAAAGwAAAAEAAAAUP///wAAARAUAAAAKAAAAAQAAAABAAAAJAAAAAsAAABfZW1iZWRkaW5ncwAAAAYACAAEAAYAAAAABgAAjP///wAAAQMQAAAAGAAAAAQAAAAAAAAABAAAAGl0ZW0AAAAAfP///7T///8AAAEFEAAAABQAAAAEAAAAAAAAAAMAAABpZF8AoP///9j///8AAAEFEAAAABgAAAAEAAAAAAAAAAUAAABHZW5yZQAAAMj///8QABQACAAGAAcADAAAABAAEAAAAAAAAQUQAAAAHAAAAAQAAAAAAAAABQAAAFRpdGxlAAAABAAEAAQAAAAAAAAA', 'organization_slug': 'csernusszilvi', 'organization_name': 'szilvi', 'creator_nickname': 'csernus.szilvi', 'creator_picture': 'https://s.gravatar.com/avatar/1c3cf3ea03776e5d3a8b3e60018c9dc4?s=480&r=pg&d=https%3A%2F%2Fcdn.auth0.com%2Favatars%2Fcs.png'}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas.map_data(\n",
    "    embeddings=np.array(plot_embeddings),\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2332609-3513-40e6-9350-2239d5c11496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_utils import distances_from_embeddings, indices_of_nearest_neighbors_from_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90474bfe-30a6-4f17-9b8d-8451ef2e4074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations_from_strings(\n",
    "    strings,\n",
    "    index_of_source_string,\n",
    "    k_nearest_neighbors=3,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    embedding_cache=embedding_cache\n",
    "):\n",
    "    # Get embeddings for all strings, movies in this case\n",
    "    embeddings = [embedding_from_string(string, model=\"text-embedding-3-small\", embedding_cache=embedding_cache) for string in strings]\n",
    "    \n",
    "    # Get embedding for our first string\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "    \n",
    "    # Get distances between our embedding and all other embeddings\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings)\n",
    "    \n",
    "    # Get indices of the nearest neighbours\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "    # print(\"List of indicies of nearest neighbors' in order, starting with the closest matches: \", indices_of_nearest_neighbors) # first distance is 0.0!! That's the target string.\n",
    "\n",
    "    # Return the first k indices\n",
    "    return indices_of_nearest_neighbors[1:k_nearest_neighbors + 1], distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6e9117de-4a89-4fbe-9cf9-018cdacf3d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movie Recommendations\n",
      "\n",
      "Title of target movie:  Alien: Covenant\n",
      "\n",
      "Ranking: 1\n",
      "Vector distance: 0.13887337027918523\n",
      "Movie Title: Prometheus\n",
      "Plot: As a spacecraft departs a planet, a humanoid alien drinks an iridescent liquid and then dissolves. The remains of the alien cascade into a waterfall. The alien's DNA strands mix with the water.\n",
      "In 20\n",
      "\n",
      "Ranking: 2\n",
      "Vector distance: 0.2571264365179512\n",
      "Movie Title: Alien Resurrection\n",
      "Plot: In 2379, two hundred years after the events of Alien 3, military scientists on the space vessel USM Auriga create a clone of Ellen Ripley, designated Ripley 8, using DNA from blood samples taken befor\n",
      "\n",
      "Ranking: 3\n",
      "Vector distance: 0.2589606411837193\n",
      "Movie Title: Aliens vs. Predator: Requiem\n",
      "Plot: Following the events of the previous film, a Predator ship leaves Earth carrying Alien facehuggers, and the body of Scar, the Predator that defeated the Alien Queen. A chestburster with traits of both\n"
     ]
    }
   ],
   "source": [
    "index_of_movie_to_get_recommendations_for = 2\n",
    "nr_of_recommendations_required = 3\n",
    "\n",
    "indices_of_recommended_movies, distances = recommendations_from_strings(\n",
    "    movie_plots, \n",
    "    index_of_movie_to_get_recommendations_for, \n",
    "    nr_of_recommendations_required, \n",
    "    \"text-embedding-3-small\", \n",
    "    embedding_cache)\n",
    "\n",
    "print(\"\\nMovie Recommendations\\n\")\n",
    "\n",
    "print(\"Title of target movie: \", movies.iloc[index_of_movie_to_get_recommendations_for].Title)\n",
    "    # print(\"Plot of target movie: \", movies.iloc[index_of_movie_to_get_recommendations_for].Plot)\n",
    "\n",
    "# print(\"indices of recommended movies: \", indices_of_recommended_movies)\n",
    "\n",
    "\n",
    "for i in range(nr_of_recommendations_required):\n",
    "        nearest_neighbor_index = indices_of_recommended_movies[i]\n",
    "        print(f\"\\nRanking: {i + 1}\")\n",
    "        print(f\"Vector distance: {distances[nearest_neighbor_index]}\")\n",
    "        print(f\"Movie Title: {movies.iloc[nearest_neighbor_index].Title}\")\n",
    "        print(f\"Plot: {movies.iloc[nearest_neighbor_index].Plot[:200]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
